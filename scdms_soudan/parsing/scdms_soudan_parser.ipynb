{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from construct import *\n",
    "\n",
    "format_word = Struct(\n",
    "    \"daq_major\" / Byte,\n",
    "    \"daq_minor\" / Byte,\n",
    "    \"data_format_major\" / Byte,\n",
    "    \"data_format_minor\" / Byte\n",
    ")\n",
    "\n",
    "two_word_file_header = Struct(\n",
    "    \"endian_indicator\" / Int32ul,\n",
    "    \"data_format\" / format_word\n",
    ")\n",
    "\n",
    "detector_hdr = Struct(\n",
    "    \"header_number\" / Int32ul,\n",
    "    \"config_record_len\" / Int32ul,\n",
    "    \"repeat_value\" / Computed(\n",
    "        lambda this: (this.config_record_len // 72) + (this.config_record_len // 144)\n",
    "    )\n",
    ")\n",
    "\n",
    "charge_config_header = Struct(\n",
    "    \"charge_config_len\" / Int32ul,\n",
    "    \"detector_code\" / Int32sl,\n",
    "    \"tower_number\" / Int32sl,\n",
    "    \"channel_post_amp\" / Int32sl,\n",
    "    \"channel_bias\" / Int32sl,\n",
    "    \"rtf_offset\" / Int32sl,\n",
    "    \"delta_t\" / Int32sl,\n",
    "    \"trigger_time\" / Int32sl,\n",
    "    \"trace_len\" / Int32sl\n",
    ")\n",
    "\n",
    "phonon_config_header = Struct(\n",
    "    \"phonon_config_len\" / Int32ul,\n",
    "    \"detector_code\" / Int32sl,\n",
    "    \"tower_number\" / Int32sl,\n",
    "    \"post_amp_gain\" / Int32sl,\n",
    "    \"qet_bias\" / Int32sl,\n",
    "    \"squid_bias\" / Int32sl,\n",
    "    \"squid_lockpoint\" / Int32sl,\n",
    "    \"rtf_offset\" / Int32sl,\n",
    "    \"variable_gain\" / Int32sl,\n",
    "    \"delta_t\" / Int32sl,\n",
    "    \"trigger_time\" / Int32sl,\n",
    "    \"trace_len\" / Int32sl\n",
    ")\n",
    "\n",
    "header_list = Struct(\n",
    "    \"header_number\" / Int32ul,\n",
    "    \"charge_config\" / If(\n",
    "        lambda this: this.header_number == 0x10002,\n",
    "        charge_config_header\n",
    "    ),\n",
    "    \"phonon_config\" / If(\n",
    "        lambda this: this.header_number == 0x10001,\n",
    "        phonon_config_header\n",
    "    )\n",
    ")\n",
    "\n",
    "event_header = Struct(\n",
    "    \"event_header_word\" / Int32ul,\n",
    "    \"event_size\" / Int32ul,\n",
    "    \"event_identifier\" / Computed(\n",
    "        lambda this: (this.event_header_word >> 16) & 0xFFFF\n",
    "    ),\n",
    "    # 0x0: Raw, 0x1: Processed, 0x2: Monte Carlo\n",
    "    \"event_class\" / Computed(\n",
    "        lambda this: (this.event_header_word >> 8) & 0xF\n",
    "    ),\n",
    "    # 0x0: Per Trigger, 0x1: Occasional, 0x2: Begin File Series, 0x3: Begin File\n",
    "    # 0x4: End File, 0x5: End File Series, 0x6: Per Trigger w/ Detectors that Cross Threshold\n",
    "    \"event_category\" / Computed(\n",
    "        lambda this: (this.event_header_word >> 12) & 0xF\n",
    "    ),\n",
    "    # 0x0: Wimp Search, 0x1: 60Co Calibration, 0x2: 60Co Low Energy Calibration,\n",
    "    # 0x3: Neutron Calibration, 0x4: Random Triggers, 0x5: Pulse Triggers\n",
    "    # 0x6: Test, 0x7: Data Monitering Event, 0x8: 137Cs Calibration\n",
    "    \"event_type\" / Computed(\n",
    "        lambda this: (this.event_header_word & 0xFF)\n",
    "    )\n",
    ")\n",
    "\n",
    "administrative_record = Struct(\n",
    "    \"admin_header\" / Int32ul,\n",
    "    \"admin_len\" / Int32ul,\n",
    "    \"series_number_1\" / Int32ul,\n",
    "    \"series_number_2\" / Int32ul,\n",
    "    \"event_number_in_series\" / Int32ul,\n",
    "    \"seconds_from_epoch\" / Int32ul,\n",
    "    # Epoch defined as Jan 1st 1904 for SUF (MAC Artifact)\n",
    "    # Epoch defined as Jan 1st 1970 for Soudan\n",
    "    \"time_from_last_event\" / Int32ul,\n",
    "    \"live_time_from_last_event\" / Int32ul\n",
    ")\n",
    "\n",
    "trace_record = Struct(\n",
    "    \"trace_header\" / Int32ul,\n",
    "    \"trace_len\" / Int32ul,\n",
    "    \"trace_bookkeeping_header\" / Int32ul,\n",
    "    \"bookkeeping_len\" / Int32ul,\n",
    "    \"digitizer_base_address\" / Int32ul,\n",
    "    \"digitizer_channel\" / Int32ul,\n",
    "    \"detector_code\" / Int32ul,\n",
    "    \"timebase_header\" / Int32ul,\n",
    "    \"timebase_len\" / Int32ul,\n",
    "    \"t0_in_ns\" / Int32ul,\n",
    "    \"delta_t_ns\" / Int32ul,\n",
    "    \"num_of_points\" / Int32ul,\n",
    "    \"second_trace_header\" / Int32ul,\n",
    "    \"num_samples\" / Int32ul\n",
    "    # Should be a power of two (1024, 2048, etc)\n",
    ")\n",
    "\n",
    "data_sample = Struct(\n",
    "    \"data_selection\" / Int32ul,\n",
    "    \"sample_a\" / Computed(\n",
    "        lambda this: (this.data_selection >> 16) & 0xFFFF\n",
    "    ),\n",
    "    \"sample_b\" / Computed(\n",
    "        lambda this: (this.data_selection & 0xFFFF)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "trace_data = Struct(\n",
    "    \"trace_rcrds\" / trace_record,\n",
    "    \"sample_data\" / Array(\n",
    "        this.trace_rcrds.num_samples // 2,\n",
    "        data_sample\n",
    "    )\n",
    ")\n",
    "\n",
    "soudan_history_buffer = Struct(\n",
    "    \"history_buffer_header\" / Int32ul,\n",
    "    \"history_buffer_len\" / Int32ul,\n",
    "    \"num_time_nvt\" / Int32ul,\n",
    "    \"time_nvt\" / Array(\n",
    "        this.num_time_nvt,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"num_veto_mask_words\" / Int32ul,\n",
    "    \"time_n_minus_veto_mask\" / Array(\n",
    "        this.num_time_nvt * this.num_veto_mask_words,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"num_trigger_times\" / Int32ul,\n",
    "    \"trigger_times\" / Array(\n",
    "        this.num_trigger_times,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"num_trigger_mask_words\" / Int32ul,\n",
    "    \"trig_times_minus_trig_mask\" / Array(\n",
    "        this.num_trigger_times * this.num_trigger_mask_words,\n",
    "        Int32ul\n",
    "    )\n",
    ")\n",
    "\n",
    "trigger_record = Struct(\n",
    "    \"trigger_header\" / Int32ul,\n",
    "    \"trigger_len\" / Int32ul,\n",
    "    \"trigger_time\" / Int32ul,\n",
    "    \"individual_trigger_masks\" / Array(\n",
    "        6,\n",
    "        Int32ul\n",
    "    )\n",
    ")\n",
    "\n",
    "tlb_trigger_mask_record = Struct(\n",
    "    \"tlb_mask_header\" / Int32ul,\n",
    "    \"tlb_len\" / Int32ul,\n",
    "    \"tower_mask\" / Array(\n",
    "        6,\n",
    "        Int32ul\n",
    "    )\n",
    ")\n",
    "\n",
    "gps_data = Struct(\n",
    "    \"tlb_mask_header\" / Int32ul,\n",
    "    \"length\" / Int32ul,\n",
    "    \"gps_year_day\" / If(\n",
    "        this.length > 0,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"gps_status_hour_minute_second\" / If(\n",
    "        this.length > 0,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"gps_microsecs_from_gps_second\" / If(\n",
    "        this.length > 0,\n",
    "        Int32ul\n",
    "    )\n",
    ")\n",
    "\n",
    "detector_trigger_threshold_data = Struct(\n",
    "    \"threshold_header\" / Int32ul,\n",
    "    \"len_to_next_header\" / Int32ul,\n",
    "    \"minimum_voltage_level\" / Int32ul,\n",
    "    \"maximum_voltage_level\" / Int32ul,\n",
    "    \"dynamic_range\" / Int32ul,\n",
    "    \"tower_number\" / Int32ul,\n",
    "    \"detector_codes\" / Array(\n",
    "        6,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"operations_codes\" / Array(\n",
    "        9,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"adc_values\" / Array(\n",
    "        54,\n",
    "        Int32ul\n",
    "    )\n",
    ")\n",
    "\n",
    "detector_trigger_rates = Struct(\n",
    "    \"detector_trigger_header\" / Int32ul,\n",
    "    \"len_to_next_header\" / Int32ul,\n",
    "    \"clocking_interval\" / Int32ul,\n",
    "    \"tower_number\" / Int32ul,\n",
    "    \"detector_codes\" / Array(\n",
    "        6,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"j_codes\" / Array(\n",
    "        5,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"counter_values\" / Array(\n",
    "        30,\n",
    "        Int32ul\n",
    "    )\n",
    ")\n",
    "\n",
    "veto_trigger_rates = Struct(\n",
    "    \"veto_trigger_header\" / Int32ul,\n",
    "    \"len_to_next_header\" / Int32ul,\n",
    "    \"clocking_interval\" / Int32ul,\n",
    "    \"num_entries\" / Int32ul,\n",
    "    \"detector_code\" / Array(\n",
    "        this.num_entries,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"counter_value_det_code\" / Array(\n",
    "        this.num_entries,\n",
    "        Int32ul\n",
    "    )\n",
    ")\n",
    "\n",
    "# Trying to generalize the logical records type\n",
    "logical_records_unused = Struct(\n",
    "    \"event_hdr\" / event_header,\n",
    "    \"next_section\" / Array(\n",
    "        6,\n",
    "        Struct(\n",
    "            \"next_header\" / Peek(Int32ul),\n",
    "            \"section\" / Switch(\n",
    "                this.next_header,\n",
    "                {\n",
    "                    0x00000002: administrative_record,\n",
    "                    0x00000011: trace_data,\n",
    "                    0x00000021: soudan_history_buffer,\n",
    "                    0x00000060: gps_data,\n",
    "                    0x00000080: trigger_record,\n",
    "                    0x00000081: tlb_trigger_mask_record,\n",
    "                    0x00000022: detector_trigger_rates,\n",
    "                    0x00000031: veto_trigger_rates\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "logical_records_generalized = Struct(\n",
    "    \"event_hdr\" / Peek(Int32ul),  # Peek to check first\n",
    "    \"next_section\" / Struct(\n",
    "        \"next_header\" / Peek(Int32ul),  # Peek without consuming\n",
    "        \"section\" / Switch(\n",
    "            lambda this: (\n",
    "                this.next_header if ((this.next_header >> 16) != 0xA980) \n",
    "                else 0xA980  # Use 0xA980 as identifier for event_header\n",
    "            ),\n",
    "            {\n",
    "                0xA980: event_header,\n",
    "                0x00000002: administrative_record,\n",
    "                0x00000011: trace_data,\n",
    "                0x00000021: soudan_history_buffer,\n",
    "                0x00000060: gps_data,\n",
    "                0x00000080: trigger_record,\n",
    "                0x00000081: tlb_trigger_mask_record,\n",
    "                0x00000022: detector_trigger_rates,\n",
    "                0x00000031: veto_trigger_rates,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# This has been working for the test file\n",
    "logical_records = Struct(\n",
    "    \"event_hdr\" / event_header,\n",
    "    \"admin_rcrd\" / administrative_record,\n",
    "    \"trigger_rcrd\" / trigger_record,\n",
    "    \"tlb_trig_mask_rcrd\" / tlb_trigger_mask_record,\n",
    "    \"gps_data\" / gps_data,\n",
    "    \"trace_data\" / Array(\n",
    "        this._root.detector_hdr.repeat_value,\n",
    "        trace_data\n",
    "    ),\n",
    "    \"soudan_buffer\" / soudan_history_buffer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "soudan = Struct(\n",
    "    \"file_hdr\" / two_word_file_header,\n",
    "    \"detector_hdr\" / detector_hdr,\n",
    "    \"hdrs\" / Array(\n",
    "        this._root.detector_hdr.repeat_value,\n",
    "        header_list\n",
    "    ),\n",
    "    \"logical_rcrds\" / GreedyRange(logical_records)\n",
    ")\n",
    "\n",
    "# Parsing a smaller number of logical_rcrds\n",
    "test = Struct(\n",
    "    \"file_hdr\" / two_word_file_header,\n",
    "    \"detector_hdr\" / detector_hdr,\n",
    "    \"hdrs\" / Array(\n",
    "        this._root.detector_hdr.repeat_value,\n",
    "        header_list\n",
    "    ),\n",
    "    \"logical_rcrds\" / Array(\n",
    "        6,\n",
    "        logical_records_generalized\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "admin_rcrd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/construct/lib/containers.py:98\u001b[0m, in \u001b[0;36mContainer.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'admin_rcrd'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 221\u001b[0m\n\u001b[1;32m    212\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../parsedh5.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# For full parsed file (not using test)\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m#output_path = \"../large_parsedh5.hdf5\"\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# For final files, save onto novateur network:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m#input_path = \"/data3/afisher/test/01130208_1838_F0006\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m#output_path = \"/data3/afisher/test/parsed_file.hdf5\"\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m \u001b[43mparse_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 119\u001b[0m, in \u001b[0;36mparse_file\u001b[0;34m(input_path, output_path)\u001b[0m\n\u001b[1;32m    115\u001b[0m admin_group_i \u001b[38;5;241m=\u001b[39m admin_rcrd_grp\u001b[38;5;241m.\u001b[39mcreate_group(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madmin_group_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madmin_header\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madmin_len\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseries_number_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseries_number_2\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m    117\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_number_in_series\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseconds_from_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_from_last_event\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    118\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlive_time_from_last_event\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mrecord_option\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madmin_rcrd\u001b[49m, attr_name):\n\u001b[1;32m    120\u001b[0m         attr_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(record_option\u001b[38;5;241m.\u001b[39madmin_rcrd, attr_name)\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;66;03m#print(f'{attr_name} value: {attr_value}')\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/construct/lib/containers.py:100\u001b[0m, in \u001b[0;36mContainer.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: admin_rcrd"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "def parse_file(input_path, output_path):\n",
    "    with open(input_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        parsed_data = test.parse(raw_data)\n",
    "\n",
    "    with h5py.File(output_path, 'w') as f:\n",
    "        \n",
    "        # Initializing header groups to fill with datasets\n",
    "        file_hdr_grp = f.create_group('file_hdr')\n",
    "        detector_hdr_grp = f.create_group('detector_hdr')\n",
    "\n",
    "        # Initializing arrays for the header information\n",
    "        file_hdr_word_list = []\n",
    "        det_hdr_list = []\n",
    "\n",
    "        # file_hdr and detector_hdr contain no arrays\n",
    "        for file_hdr_type in parsed_data.file_hdr:\n",
    "            hdr_type_grp = file_hdr_grp.create_group(f'{file_hdr_type}')\n",
    "            file_hdr_word_list.append(hdr_type_grp)\n",
    "            if file_hdr_type == 'data_format':\n",
    "                for attr_name in ['daq_major', 'daq_minor', 'data_format_major', 'data_format_minor']:\n",
    "                    if hasattr(parsed_data.file_hdr.data_format, attr_name):\n",
    "                        attr_value = getattr(parsed_data.file_hdr.data_format, attr_name)\n",
    "                        hdr_type_grp.create_dataset(attr_name, data=attr_value)\n",
    "            elif file_hdr_type == \"endian_indicator\":\n",
    "                hdr_type_grp.create_dataset('endian_indicator', data=parsed_data.file_hdr.endian_indicator)\n",
    "        \n",
    "        for det_data_type in parsed_data.detector_hdr:\n",
    "            det_type_grp = detector_hdr_grp.create_group(f'{det_data_type}')\n",
    "            det_hdr_list.append(det_type_grp)\n",
    "            if det_data_type == 'header_number':\n",
    "                det_type_grp.create_dataset('header_number', data=parsed_data.detector_hdr.header_number)\n",
    "            elif det_data_type == 'config_record_len':\n",
    "                det_type_grp.create_dataset('config_record_len', data=parsed_data.detector_hdr.config_record_len)\n",
    "            elif det_data_type == 'repeat_value':\n",
    "                det_type_grp.create_dataset('repeat_value', data=parsed_data.detector_hdr.repeat_value)\n",
    "\n",
    "\n",
    "        # hdrs contains an array of charge and phonon headers\n",
    "        hdrs_grp           = f.create_group('hdrs')\n",
    "        charge_config_grp  = hdrs_grp.create_group('charge_config')\n",
    "        phonon_config_grp  = hdrs_grp.create_group('phonon_config')\n",
    "        hdrs_array         = []\n",
    "        charge_config_list = []\n",
    "        phonon_config_list = []\n",
    "\n",
    "        # Create groups for each header and populate them with relevant datasets\n",
    "        for i, header in enumerate(parsed_data.hdrs):\n",
    "            # Collecting charge_config data\n",
    "            if header.header_number == 0x10002:\n",
    "                # HDF5 groups require unique names if at same level of structure\n",
    "                charge_config_hdr_grp = charge_config_grp.create_group(f'charge_config_{i}')\n",
    "                charge_config_list.append(charge_config_hdr_grp)\n",
    "                hdrs_array.append(charge_config_hdr_grp)\n",
    "                for attr_name in ['charge_config_len', 'detector_code', 'tower_number',\n",
    "                                  'channel_post_amp', 'rtf_offset', 'delta_t', 'trigger_time',\n",
    "                                  'trace_len']:\n",
    "                    if hasattr(header.charge_config, attr_name):\n",
    "                        attr_value = getattr(header.charge_config, attr_name)\n",
    "                        charge_config_hdr_grp.create_dataset(attr_name, data=attr_value)\n",
    "                \n",
    "            # Collecting phonon_config data\n",
    "            elif header.header_number == 0x10001:\n",
    "                phonon_config_hdr_grp = phonon_config_grp.create_group(f'phonon_config_{i}')\n",
    "                phonon_config_list.append(header)\n",
    "                hdrs_array.append(phonon_config_hdr_grp)\n",
    "                for attr_name in ['phonon_config_len', 'detector_code', 'tower_number',\n",
    "                                  'post_amp_gain', 'qet_bias', 'squid_bias', 'squid_lockpoint',\n",
    "                                  'rtf_offset', 'variable_gain', 'delta_t', 'trigger_time', 'trace_len']:\n",
    "                    if hasattr(header.phonon_config, attr_name):\n",
    "                        attr_value = getattr(header.phonon_config, attr_name)\n",
    "                        phonon_config_hdr_grp.create_dataset(attr_name, data=attr_value)\n",
    "        \n",
    "        # Creating groups that can hold each event's records\n",
    "        logical_rcrd_grp       = f.create_group('logical_rcrds')\n",
    "        pulse_grp              = logical_rcrd_grp.create_group('pulse_data')\n",
    "        event_hdr_grp          = logical_rcrd_grp.create_group('event_hdr')\n",
    "        admin_rcrd_grp         = logical_rcrd_grp.create_group('admin_rcrd')\n",
    "        trigger_rcrd_grp       = logical_rcrd_grp.create_group('trigger_rcrd')\n",
    "        tlb_trig_mask_rcrd_grp = logical_rcrd_grp.create_group('tlb_trig_mask_rcrd')\n",
    "        gps_data_grp           = logical_rcrd_grp.create_group('gps_data')\n",
    "        trace_data_grp         = logical_rcrd_grp.create_group('trace_data')\n",
    "        soudan_buffer_grp      = logical_rcrd_grp.create_group('soudan_buffer')\n",
    "\n",
    "        # Initializing arrays to store the created groups of logical_rcrd data\n",
    "        logical_rcrd_array       = []\n",
    "        event_hdr_array          = []\n",
    "        admin_rcrd_array         = []\n",
    "        trigger_rcrd_array       = []\n",
    "        tlb_trig_mask_rcrd_array = []\n",
    "        gps_data_array           = []\n",
    "        trace_data_array         = []\n",
    "        soudan_buffer_array      = []\n",
    "        # Array for storing trace record data\n",
    "        pulse_array              = []\n",
    "\n",
    "        for i, record_option in enumerate(parsed_data.logical_rcrds):\n",
    "            # Storing event_hdr data\n",
    "            events = []\n",
    "            # Loop through attributes of event_hdr and store them in event_group_i\n",
    "            event_group_i = event_hdr_grp.create_group(f'event_group_{i}')\n",
    "            for attr_name in ['event_header_word', 'event_size', 'event_identifier',\n",
    "                            'event_class', 'event_category', 'event_type']:\n",
    "                if hasattr(record_option.event_hdr, attr_name):\n",
    "                    attr_value = getattr(record_option.event_hdr, attr_name)\n",
    "                    event_data = event_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                    events.append(event_data)\n",
    "            event_hdr_array.append(events)\n",
    "\n",
    "            # Storing admin_rcrd data\n",
    "            admins = []\n",
    "            # Loop through attributes of admin_rcrd and store them in admin_group_i\n",
    "            admin_group_i = admin_rcrd_grp.create_group(f'admin_group_{i}')\n",
    "            for attr_name in ['admin_header', 'admin_len', 'series_number_1', 'series_number_2', \n",
    "                              'event_number_in_series', 'seconds_from_epoch', 'time_from_last_event',\n",
    "                              'live_time_from_last_event']:\n",
    "                if hasattr(record_option.admin_rcrd, attr_name):\n",
    "                    attr_value = getattr(record_option.admin_rcrd, attr_name)\n",
    "                    #print(f'{attr_name} value: {attr_value}')\n",
    "                    admin_data = admin_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                    admins.append(admin_data)\n",
    "\n",
    "            admin_rcrd_array.append(admins)\n",
    "\n",
    "            # Storing trigger_rcrd data\n",
    "            triggers = []\n",
    "            # Loop through attributes of trigger_rcrd and store them in trigger_group_i\n",
    "            trigger_group_i = trigger_rcrd_grp.create_group(f'trigger_rcrd_group_{i}')\n",
    "            for attr_name in ['trigger_header', 'trigger_len', 'trigger_time', 'individual_trigger_masks']:\n",
    "                if hasattr(record_option.trigger_rcrd, attr_name):\n",
    "                    attr_value = getattr(record_option.trigger_rcrd, attr_name)\n",
    "                    trigger_data = trigger_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                    triggers.append(trigger_data)\n",
    "            trigger_rcrd_array.append(triggers)\n",
    "\n",
    "            # Storing tlb_trig_mask_rcrd data\n",
    "            tlb_trig_mask = []\n",
    "            # Loop through attributes of tlb_trig_mask_rcrd and store them in tlb_trig_group_i\n",
    "            tlb_trig_group_i = tlb_trig_mask_rcrd_grp.create_group(f'tlb_trig_group_{i}')\n",
    "            for attr_name in ['tlb_mask_header', 'tlb_len', 'tower_mask']:\n",
    "                if hasattr(record_option.tlb_trig_mask_rcrd, attr_name):\n",
    "                    attr_value = getattr(record_option.tlb_trig_mask_rcrd, attr_name)\n",
    "                    tlb_trig_data = tlb_trig_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                    tlb_trig_mask.append(tlb_trig_data)\n",
    "            tlb_trig_mask_rcrd_array.append(tlb_trig_mask)\n",
    "\n",
    "            # Storing gps_data\n",
    "            gps = []\n",
    "            # Loop through attributes of gps_data and store them in gps_data_group_i\n",
    "            gps_data_group_i = gps_data_grp.create_group(f'gps_data_{i}')\n",
    "            # Only tlb_mask_header and length have values if length = 0\n",
    "            if record_option.gps_data.length == 0:\n",
    "                for attr_name in ['tlb_mask_header', 'length']:\n",
    "                    if hasattr(record_option.gps_data, attr_name):\n",
    "                        attr_value = getattr(record_option.gps_data, attr_name)\n",
    "                        gps_dataset = gps_data_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                        gps.append(gps_dataset)\n",
    "            else:\n",
    "                for attr_name in ['tlb_mask_header', 'length', 'gps_year_day', 'gps_status_hour_minute',\n",
    "                                  'gps_microsecs_from_gps_second']:\n",
    "                    if hasattr(record_option.gps_data, attr_name):\n",
    "                        attr_value = getattr(record_option.gps_data, attr_name)\n",
    "                        gps_dataset = gps_data_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                        gps.append(gps_dataset)\n",
    "            gps_data_array.append(gps)\n",
    "\n",
    "            # Loop through attributes of trace_data.trace_rcrds and store them in trace_record_group_i\n",
    "            trace_data_group_i = trace_data_grp.create_group(f'trace_data_group_{i}')\n",
    "            for trace_idx, trace_data in enumerate(record_option.trace_data):\n",
    "                trace = []\n",
    "                # Add sample data to trace\n",
    "                for data in trace_data.sample_data:\n",
    "                    trace.append(data.sample_a)\n",
    "                    trace.append(data.sample_b)\n",
    "\n",
    "                # Collect related trace record information\n",
    "                trace_rcrd = []\n",
    "                trace_record_group_i = trace_data_group_i.create_group(f'trace_record_group_{trace_idx}')\n",
    "                for attr_name in ['trace_header', 'trace_len', 'trace_bookkeeping_header', 'bookkeeping_len',\n",
    "                                  'digitizer_base_address', 'digitizer_channel', 'detector_code', 'timebase_header',\n",
    "                                  'timebase_len', 't0_in_ns', 'delta_t_ns', 'num_of_points', 'second_trace_header',\n",
    "                                  'num_samples']:\n",
    "                    if hasattr(trace_data.trace_rcrds, attr_name):\n",
    "                        attr_value = getattr(trace_data.trace_rcrds, attr_name)\n",
    "                        trace_rcrd_dataset = trace_record_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                        trace_rcrd.append(trace_rcrd_dataset)\n",
    "            pulse_array.append(trace)\n",
    "            trace_data_array.append(trace_rcrd)\n",
    "            #print(f'Data samples in event {i}: {len(trace)}')\n",
    "\n",
    "            # Storing soudan_buffer data\n",
    "            soudan_buffer = []\n",
    "            # Loop through attributes of soudan_buffer and store them in soudan_buffer_group_i\n",
    "            soudan_buffer_group_i = soudan_buffer_grp.create_group(f'soudan_buffer_group_{i}')\n",
    "            for attr_name in ['history_buffer_header', 'history_buffer_len', 'num_time_nvt', 'time_nvt',\n",
    "                              'num_veto_mask_words', 'time_n_minus_veto_mask', 'num_trigger_times', \n",
    "                              'trigger_times', 'num_trigger_mask_words', 'trig_times_minus_trig_mask']:\n",
    "                if hasattr(record_option.soudan_buffer, attr_name):\n",
    "                    attr_value = getattr(record_option.soudan_buffer, attr_name)\n",
    "                    soudan_buffer_dataset = soudan_buffer_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                    soudan_buffer.append(soudan_buffer_dataset)\n",
    "            soudan_buffer_array.append(soudan_buffer)\n",
    "        \n",
    "        logical_rcrd_array.append([events, admins, triggers, tlb_trig_mask, gps, soudan_buffer])\n",
    "        pulse_grp.create_dataset('traces', data=pulse_array)\n",
    "        print(f\"Number of events parsed: {len(pulse_array)}\")\n",
    "\n",
    "\n",
    "input_path  = \"../01120210_0727_F0114\"\n",
    "output_path = \"../parsedh5.hdf5\"\n",
    "# For full parsed file (not using test)\n",
    "#output_path = \"../large_parsedh5.hdf5\"\n",
    "# For final files, save onto novateur network:\n",
    "#output_path = \"/data3/afisher/soudan_output/parsed.txt\"\n",
    "\n",
    "#input_path = \"/data3/afisher/test/01130208_1838_F0006\"\n",
    "#output_path = \"/data3/afisher/test/parsed_file.hdf5\"\n",
    "\n",
    "parse_file(input_path, output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Switch Struct:\n",
    "StreamError: Error in path (parsing) -> logical_rcrds -> soudan_buffer -> time_n_minus_veto_mask\n",
    "stream read less than specified amount, expected 4, found 0\n",
    "\n",
    "### With Switch Struct:\n",
    "StreamError: Error in path (parsing) -> logical_rcrds -> next_section -> section -> sample_data -> data_selection\n",
    "stream read less than specified amount, expected 4, found 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 127 (3314149119.py, line 138)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[70], line 138\u001b[0;36m\u001b[0m\n\u001b[0;31m    input_path  = \"../01120210_0727_F0114\"\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 127\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "def parse_file(input_path, output_path):\n",
    "    with open(input_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        parsed_data = test.parse(raw_data)\n",
    "\n",
    "    with h5py.File(output_path, 'w') as f:\n",
    "        \n",
    "        # Initializing header groups to fill with datasets\n",
    "        file_hdr_grp = f.create_group('file_hdr')\n",
    "        detector_hdr_grp = f.create_group('detector_hdr')\n",
    "\n",
    "        # Initializing arrays for the header information\n",
    "        file_hdr_word_list = []\n",
    "        det_hdr_list = []\n",
    "\n",
    "        # file_hdr and detector_hdr contain no arrays\n",
    "        for file_hdr_type in parsed_data.file_hdr:\n",
    "            hdr_type_grp = file_hdr_grp.create_group(f'{file_hdr_type}')\n",
    "            file_hdr_word_list.append(hdr_type_grp)\n",
    "            if file_hdr_type == 'data_format':\n",
    "                for attr_name in ['daq_major', 'daq_minor', 'data_format_major', 'data_format_minor']:\n",
    "                    if hasattr(parsed_data.file_hdr.data_format, attr_name):\n",
    "                        attr_value = getattr(parsed_data.file_hdr.data_format, attr_name)\n",
    "                        hdr_type_grp.create_dataset(attr_name, data=attr_value)\n",
    "            elif file_hdr_type == \"endian_indicator\":\n",
    "                hdr_type_grp.create_dataset('endian_indicator', data=parsed_data.file_hdr.endian_indicator)\n",
    "        \n",
    "        for det_data_type in parsed_data.detector_hdr:\n",
    "            det_type_grp = detector_hdr_grp.create_group(f'{det_data_type}')\n",
    "            det_hdr_list.append(det_type_grp)\n",
    "            if det_data_type == 'header_number':\n",
    "                det_type_grp.create_dataset('header_number', data=parsed_data.detector_hdr.header_number)\n",
    "            elif det_data_type == 'config_record_len':\n",
    "                det_type_grp.create_dataset('config_record_len', data=parsed_data.detector_hdr.config_record_len)\n",
    "            elif det_data_type == 'repeat_value':\n",
    "                det_type_grp.create_dataset('repeat_value', data=parsed_data.detector_hdr.repeat_value)\n",
    "\n",
    "\n",
    "        # hdrs contains an array of charge and phonon headers\n",
    "        hdrs_grp           = f.create_group('hdrs')\n",
    "        charge_config_grp  = hdrs_grp.create_group('charge_config')\n",
    "        phonon_config_grp  = hdrs_grp.create_group('phonon_config')\n",
    "        hdrs_array         = []\n",
    "        charge_config_list = []\n",
    "        phonon_config_list = []\n",
    "\n",
    "        # Create groups for each header and populate them with relevant datasets\n",
    "        for i, header in enumerate(parsed_data.hdrs):\n",
    "            # Collecting charge_config data\n",
    "            if header.header_number == 0x10002:\n",
    "                # HDF5 groups require unique names if at same level of structure\n",
    "                charge_config_hdr_grp = charge_config_grp.create_group(f'charge_config_{i}')\n",
    "                charge_config_list.append(charge_config_hdr_grp)\n",
    "                hdrs_array.append(charge_config_hdr_grp)\n",
    "                for attr_name in ['charge_config_len', 'detector_code', 'tower_number',\n",
    "                                  'channel_post_amp', 'rtf_offset', 'delta_t', 'trigger_time',\n",
    "                                  'trace_len']:\n",
    "                    if hasattr(header.charge_config, attr_name):\n",
    "                        attr_value = getattr(header.charge_config, attr_name)\n",
    "                        charge_config_hdr_grp.create_dataset(attr_name, data=attr_value)\n",
    "                \n",
    "            # Collecting phonon_config data\n",
    "            elif header.header_number == 0x10001:\n",
    "                phonon_config_hdr_grp = phonon_config_grp.create_group(f'phonon_config_{i}')\n",
    "                phonon_config_list.append(header)\n",
    "                hdrs_array.append(phonon_config_hdr_grp)\n",
    "                for attr_name in ['phonon_config_len', 'detector_code', 'tower_number',\n",
    "                                  'post_amp_gain', 'qet_bias', 'squid_bias', 'squid_lockpoint',\n",
    "                                  'rtf_offset', 'variable_gain', 'delta_t', 'trigger_time', 'trace_len']:\n",
    "                    if hasattr(header.phonon_config, attr_name):\n",
    "                        attr_value = getattr(header.phonon_config, attr_name)\n",
    "                        phonon_config_hdr_grp.create_dataset(attr_name, data=attr_value)\n",
    "        # For use in group creation\n",
    "        logical_record_options = {\n",
    "            0xA980: \"event_header\",\n",
    "            0x00000002: \"administrative_record\",\n",
    "            0x00000011: \"trace_data\",\n",
    "            0x00000021: \"soudan_history_buffer\",\n",
    "            0x00000060: \"gps_data\",\n",
    "            0x00000080: \"trigger_record\",\n",
    "            0x00000081: \"tlb_trigger_mask_record\",\n",
    "            0x00000022: \"detector_trigger_rates\",\n",
    "            0x00000031: \"veto_trigger_rates\",\n",
    "        }\n",
    "\n",
    "        # Creating groups that can hold each event's records\n",
    "        logical_rcrd_grp       = f.create_group('logical_rcrds')\n",
    "        pulse_grp              = logical_rcrd_grp.create_group('pulse_data')\n",
    "        event_hdr_grp          = logical_rcrd_grp.create_group('event_hdr')\n",
    "        admin_rcrd_grp         = logical_rcrd_grp.create_group('admin_rcrd')\n",
    "        trigger_rcrd_grp       = logical_rcrd_grp.create_group('trigger_rcrd')\n",
    "        tlb_trig_mask_rcrd_grp = logical_rcrd_grp.create_group('tlb_trig_mask_rcrd')\n",
    "        gps_data_grp           = logical_rcrd_grp.create_group('gps_data')\n",
    "        trace_data_grp         = logical_rcrd_grp.create_group('trace_data')\n",
    "        soudan_buffer_grp      = logical_rcrd_grp.create_group('soudan_buffer')\n",
    "\n",
    "        # Initializing arrays to store the created groups of logical_rcrd data\n",
    "        logical_rcrd_array       = []\n",
    "        event_hdr_array          = []\n",
    "        admin_rcrd_array         = []\n",
    "        trigger_rcrd_array       = []\n",
    "        tlb_trig_mask_rcrd_array = []\n",
    "        gps_data_array           = []\n",
    "        trace_data_array         = []\n",
    "        soudan_buffer_array      = []\n",
    "        # Array for storing trace record data\n",
    "        pulse_array              = []\n",
    "\n",
    "        for i, record_option in enumerate(parsed_data.logical_rcrds):\n",
    "            # Storing event_hdr data\n",
    "            events = []\n",
    "            # Loop through attributes of event_hdr and store them in event_group_i\n",
    "            event_group_i = event_hdr_grp.create_group(f'event_group_{i}')\n",
    "            for attr_name in ['event_header_word', 'event_size', 'event_identifier',\n",
    "                            'event_class', 'event_category', 'event_type']:\n",
    "                if hasattr(record_option.event_hdr, attr_name):\n",
    "                    attr_value = getattr(record_option.event_hdr, attr_name)\n",
    "                    event_data = event_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                    events.append(event_data)\n",
    "            event_hdr_array.append(events)\n",
    "\n",
    "            # Iterate through logical_rcrds.next_section.section to store data\n",
    "            section_type = record_option.next_section.section\n",
    "            admin_group_i = admin_rcrd_grp.create_group(f'admin_group_{i}')\n",
    "            for j, section in enumerate(section_type):\n",
    "                \n",
    "                #print(f'Section: {section}, record option: {i}, section # {j}')\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "                \n",
    "            \n",
    "\n",
    "input_path  = \"../01120210_0727_F0114\"\n",
    "output_path = \"../generalized_test_parsedh5.hdf5\"\n",
    "\n",
    "parse_file(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing admin_rcrd data\n",
    "            admins = []\n",
    "            # Loop through attributes of admin_rcrd and store them in admin_group_i\n",
    "            admin_group_i = admin_rcrd_grp.create_group(f'admin_group_{i}')\n",
    "            for attr_name in ['admin_header', 'admin_len', 'series_number_1', 'series_number_2', \n",
    "                              'event_number_in_series', 'seconds_from_epoch', 'time_from_last_event',\n",
    "                              'live_time_from_last_event']:\n",
    "                if hasattr(record_option.admin_rcrd, attr_name):\n",
    "                    print(attr_name)\n",
    "\n",
    "                if hasattr(record_option.admin_rcrd, attr_name):\n",
    "                                    attr_value = getattr(record_option.admin_rcrd, attr_name)\n",
    "                                    #print(f'{attr_name} value: {attr_value}')\n",
    "                                    admin_data = admin_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                                    admins.append(admin_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
