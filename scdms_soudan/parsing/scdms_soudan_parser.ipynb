{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from construct import *\n",
    "\n",
    "format_word = Struct(\n",
    "    \"daq_major\" / Byte,\n",
    "    \"daq_minor\" / Byte,\n",
    "    \"data_format_major\" / Byte,\n",
    "    \"data_format_minor\" / Byte\n",
    ")\n",
    "\n",
    "two_word_file_header = Struct(\n",
    "    \"endian_indicator\" / Int32ul,\n",
    "    \"data_format\" / format_word\n",
    ")\n",
    "\n",
    "detector_hdr = Struct(\n",
    "    \"header_number\" / Int32ul,\n",
    "    \"config_record_len\" / Int32ul,\n",
    "    \"repeat_value\" / Computed(\n",
    "        lambda this: (this.config_record_len // 72) + (this.config_record_len // 144)\n",
    "    )\n",
    ")\n",
    "\n",
    "charge_config_header = Struct(\n",
    "    \"charge_config_len\" / Int32ul,\n",
    "    \"detector_code\" / Int32sl,\n",
    "    \"tower_number\" / Int32sl,\n",
    "    \"channel_post_amp\" / Int32sl,\n",
    "    \"channel_bias\" / Int32sl,\n",
    "    \"rtf_offset\" / Int32sl,\n",
    "    \"delta_t\" / Int32sl,\n",
    "    \"trigger_time\" / Int32sl,\n",
    "    \"trace_len\" / Int32sl\n",
    ")\n",
    "\n",
    "phonon_config_header = Struct(\n",
    "    \"phonon_config_len\" / Int32ul,\n",
    "    \"detector_code\" / Int32sl,\n",
    "    \"tower_number\" / Int32sl,\n",
    "    \"post_amp_gain\" / Int32sl,\n",
    "    \"qet_bias\" / Int32sl,\n",
    "    \"squid_bias\" / Int32sl,\n",
    "    \"squid_lockpoint\" / Int32sl,\n",
    "    \"rtf_offset\" / Int32sl,\n",
    "    \"variable_gain\" / Int32sl,\n",
    "    \"delta_t\" / Int32sl,\n",
    "    \"trigger_time\" / Int32sl,\n",
    "    \"trace_len\" / Int32sl\n",
    ")\n",
    "\n",
    "header_list = Struct(\n",
    "    \"header_number\" / Int32ul,\n",
    "    \"charge_config\" / If(\n",
    "        lambda this: this.header_number == 0x10002,\n",
    "        charge_config_header\n",
    "    ),\n",
    "    \"phonon_config\" / If(\n",
    "        lambda this: this.header_number == 0x10001,\n",
    "        phonon_config_header\n",
    "    )\n",
    ")\n",
    "\n",
    "event_header = Struct(\n",
    "    \"event_header_word\" / Int32ul,\n",
    "    \"event_size\" / Int32ul,\n",
    "    \"event_identifier\" / Computed(\n",
    "        lambda this: (this.event_header_word >> 16) & 0xFFFF\n",
    "    ),\n",
    "    # 0x0: Raw, 0x1: Processed, 0x2: Monte Carlo\n",
    "    \"event_class\" / Computed(\n",
    "        lambda this: (this.event_header_word >> 8) & 0xF\n",
    "    ),\n",
    "    # 0x0: Per Trigger, 0x1: Occasional, 0x2: Begin File Series, 0x3: Begin File\n",
    "    # 0x4: End File, 0x5: End File Series, 0x6: Per Trigger w/ Detectors that Cross Threshold\n",
    "    \"event_category\" / Computed(\n",
    "        lambda this: (this.event_header_word >> 12) & 0xF\n",
    "    ),\n",
    "    # 0x0: Wimp Search, 0x1: 60Co Calibration, 0x2: 60Co Low Energy Calibration,\n",
    "    # 0x3: Neutron Calibration, 0x4: Random Triggers, 0x5: Pulse Triggers\n",
    "    # 0x6: Test, 0x7: Data Monitering Event, 0x8: 137Cs Calibration\n",
    "    \"event_type\" / Computed(\n",
    "        lambda this: (this.event_header_word & 0xFF)\n",
    "    )\n",
    ")\n",
    "\n",
    "administrative_record = Struct(\n",
    "    \"admin_header\" / Int32ul,\n",
    "    \"admin_len\" / Int32ul,\n",
    "    \"series_number_1\" / Int32ul,\n",
    "    \"series_number_2\" / Int32ul,\n",
    "    \"event_number_in_series\" / Int32ul,\n",
    "    \"seconds_from_epoch\" / Int32ul,\n",
    "    # Epoch defined as Jan 1st 1904 for SUF (MAC Artifact)\n",
    "    # Epoch defined as Jan 1st 1970 for Soudan\n",
    "    \"time_from_last_event\" / Int32ul,\n",
    "    \"live_time_from_last_event\" / Int32ul\n",
    ")\n",
    "\n",
    "trace_record = Struct(\n",
    "    \"trace_header\" / Int32ul,\n",
    "    \"trace_len\" / Int32ul,\n",
    "    \"trace_bookkeeping_header\" / Int32ul,\n",
    "    \"bookkeeping_len\" / Int32ul,\n",
    "    \"digitizer_base_address\" / Int32ul,\n",
    "    \"digitizer_channel\" / Int32ul,\n",
    "    \"detector_code\" / Int32ul,\n",
    "    \"timebase_header\" / Int32ul,\n",
    "    \"timebase_len\" / Int32ul,\n",
    "    \"t0_in_ns\" / Int32ul,\n",
    "    \"delta_t_ns\" / Int32ul,\n",
    "    \"num_of_points\" / Int32ul,\n",
    "    \"second_trace_header\" / Int32ul,\n",
    "    \"num_samples\" / Int32ul\n",
    "    # Should be a power of two (1024, 2048, etc)\n",
    ")\n",
    "\n",
    "data_sample = Struct(\n",
    "    \"data_selection\" / Int32ul,\n",
    "    \"sample_a\" / Computed(\n",
    "        lambda this: (this.data_selection >> 16) & 0xFFFF\n",
    "    ),\n",
    "    \"sample_b\" / Computed(\n",
    "        lambda this: (this.data_selection & 0xFFFF)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "trace_data = Struct(\n",
    "    \"trace_rcrds\" / trace_record,\n",
    "    \"sample_data\" / Array(\n",
    "        this.trace_rcrds.num_samples // 2,\n",
    "        data_sample\n",
    "    )\n",
    ")\n",
    "\n",
    "soudan_history_buffer = Struct(\n",
    "    \"history_buffer_header\" / Int32ul,\n",
    "    \"history_buffer_len\" / Int32ul,\n",
    "    \"num_time_nvt\" / Int32ul,\n",
    "    \"time_nvt\" / Array(\n",
    "        this.num_time_nvt,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"num_veto_mask_words\" / Int32ul,\n",
    "    \"time_n_minus_veto_mask\" / Array(\n",
    "        this.num_time_nvt * this.num_veto_mask_words,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"num_trigger_times\" / Int32ul,\n",
    "    \"trigger_times\" / Array(\n",
    "        this.num_trigger_times,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"num_trigger_mask_words\" / Int32ul,\n",
    "    \"trig_times_minus_trig_mask\" / Array(\n",
    "        this.num_trigger_times * this.num_trigger_mask_words,\n",
    "        Int32ul\n",
    "    )\n",
    ")\n",
    "\n",
    "trigger_record = Struct(\n",
    "    \"trigger_header\" / Int32ul,\n",
    "    \"trigger_len\" / Int32ul,\n",
    "    \"trigger_time\" / Int32ul,\n",
    "    \"individual_trigger_masks\" / Array(\n",
    "        6,\n",
    "        Int32ul\n",
    "    )\n",
    ")\n",
    "\n",
    "tlb_trigger_mask_record = Struct(\n",
    "    \"tlb_mask_header\" / Int32ul,\n",
    "    \"tlb_len\" / Int32ul,\n",
    "    \"tower_mask\" / Array(\n",
    "        6,\n",
    "        Int32ul\n",
    "    )\n",
    ")\n",
    "\n",
    "gps_data = Struct(\n",
    "    \"tlb_mask_header\" / Int32ul,\n",
    "    \"length\" / Int32ul,\n",
    "    \"gps_year_day\" / If(\n",
    "        this.length > 0,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"gps_status_hour_minute_second\" / If(\n",
    "        this.length > 0,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"gps_microsecs_from_gps_second\" / If(\n",
    "        this.length > 0,\n",
    "        Int32ul\n",
    "    )\n",
    ")\n",
    "\n",
    "detector_trigger_threshold_data = Struct(\n",
    "    \"threshold_header\" / Int32ul,\n",
    "    \"len_to_next_header\" / Int32ul,\n",
    "    \"minimum_voltage_level\" / Int32ul,\n",
    "    \"maximum_voltage_level\" / Int32ul,\n",
    "    \"dynamic_range\" / Int32ul,\n",
    "    \"tower_number\" / Int32ul,\n",
    "    \"detector_codes\" / Array(\n",
    "        6,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"operations_codes\" / Array(\n",
    "        9,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"adc_values\" / Array(\n",
    "        54,\n",
    "        Int32ul\n",
    "    )\n",
    ")\n",
    "\n",
    "detector_trigger_rates = Struct(\n",
    "    \"detector_trigger_header\" / Int32ul,\n",
    "    \"len_to_next_header\" / Int32ul,\n",
    "    \"clocking_interval\" / Int32ul,\n",
    "    \"tower_number\" / Int32ul,\n",
    "    \"detector_codes\" / Array(\n",
    "        6,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"j_codes\" / Array(\n",
    "        5,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"counter_values\" / Array(\n",
    "        30,\n",
    "        Int32ul\n",
    "    )\n",
    ")\n",
    "\n",
    "veto_trigger_rates = Struct(\n",
    "    \"veto_trigger_header\" / Int32ul,\n",
    "    \"len_to_next_header\" / Int32ul,\n",
    "    \"clocking_interval\" / Int32ul,\n",
    "    \"num_entries\" / Int32ul,\n",
    "    \"detector_code\" / Array(\n",
    "        this.num_entries,\n",
    "        Int32ul\n",
    "    ),\n",
    "    \"counter_value_det_code\" / Array(\n",
    "        this.num_entries,\n",
    "        Int32ul\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Generalized logical record\n",
    "logical_records = Struct(\n",
    "    \"event_hdr\" / Peek(Int32ul),  # Peek to check first\n",
    "    \"next_section\" / Struct(\n",
    "        \"next_header\" / Peek(Int32ul),  # Peek without consuming\n",
    "        \"section\" / Switch(\n",
    "            lambda this: (\n",
    "                this.next_header if ((this.next_header >> 16) != 0xA980) \n",
    "                else 0xA980  # Use 0xA980 as identifier for event_header\n",
    "            ),\n",
    "            {\n",
    "                0xA980: event_header,\n",
    "                0x00000002: administrative_record,\n",
    "                0x00000011: trace_data,\n",
    "                0x00000021: soudan_history_buffer,\n",
    "                0x00000060: gps_data,\n",
    "                0x00000080: trigger_record,\n",
    "                0x00000081: tlb_trigger_mask_record,\n",
    "                0x00000022: detector_trigger_rates,\n",
    "                0x00000031: veto_trigger_rates,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "soudan = Struct(\n",
    "    \"file_hdr\" / two_word_file_header,\n",
    "    \"detector_hdr\" / detector_hdr,\n",
    "    \"hdrs\" / Array(\n",
    "        this._root.detector_hdr.repeat_value,\n",
    "        header_list\n",
    "    ),\n",
    "    \"logical_rcrds\" / GreedyRange(logical_records)\n",
    ")\n",
    "\n",
    "test = Struct(\n",
    "    \"file_hdr\" / two_word_file_header,\n",
    "    \"detector_hdr\" / detector_hdr,\n",
    "    \"hdrs\" / Array(\n",
    "        this._root.detector_hdr.repeat_value,\n",
    "        header_list\n",
    "    ),\n",
    "    \"logical_rcrds\" / Array(\n",
    "        100,\n",
    "        logical_records\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def parse_file(input_path, output_path):\n",
    "    with open(input_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        parsed_data = soudan.parse(raw_data)\n",
    "\n",
    "    with h5py.File(output_path, 'w') as f:\n",
    "        \n",
    "        # Initializing header groups to fill with datasets\n",
    "        file_hdr_grp = f.create_group('file_hdr')\n",
    "        detector_hdr_grp = f.create_group('detector_hdr')\n",
    "\n",
    "        # Initializing arrays for the header information\n",
    "        file_hdr_word_list = []\n",
    "        det_hdr_list = []\n",
    "\n",
    "        # file_hdr and detector_hdr contain no arrays\n",
    "        for file_hdr_type in parsed_data.file_hdr:\n",
    "            hdr_type_grp = file_hdr_grp.create_group(f'{file_hdr_type}')\n",
    "            file_hdr_word_list.append(hdr_type_grp)\n",
    "            if file_hdr_type == 'data_format':\n",
    "                for attr_name in ['daq_major', 'daq_minor', 'data_format_major', 'data_format_minor']:\n",
    "                    if hasattr(parsed_data.file_hdr.data_format, attr_name):\n",
    "                        attr_value = getattr(parsed_data.file_hdr.data_format, attr_name)\n",
    "                        hdr_type_grp.create_dataset(attr_name, data=attr_value)\n",
    "            elif file_hdr_type == \"endian_indicator\":\n",
    "                hdr_type_grp.create_dataset('endian_indicator', data=parsed_data.file_hdr.endian_indicator)\n",
    "        \n",
    "        for det_data_type in parsed_data.detector_hdr:\n",
    "            det_type_grp = detector_hdr_grp.create_group(f'{det_data_type}')\n",
    "            det_hdr_list.append(det_type_grp)\n",
    "            if det_data_type == 'header_number':\n",
    "                det_type_grp.create_dataset('header_number', data=parsed_data.detector_hdr.header_number)\n",
    "            elif det_data_type == 'config_record_len':\n",
    "                det_type_grp.create_dataset('config_record_len', data=parsed_data.detector_hdr.config_record_len)\n",
    "            elif det_data_type == 'repeat_value':\n",
    "                det_type_grp.create_dataset('repeat_value', data=parsed_data.detector_hdr.repeat_value)\n",
    "\n",
    "\n",
    "        # hdrs contains an array of charge and phonon headers\n",
    "        hdrs_grp           = f.create_group('hdrs')\n",
    "        charge_config_grp  = hdrs_grp.create_group('charge_config')\n",
    "        phonon_config_grp  = hdrs_grp.create_group('phonon_config')\n",
    "        hdrs_array         = []\n",
    "        charge_config_list = []\n",
    "        phonon_config_list = []\n",
    "\n",
    "        # Create groups for each header and populate them with relevant datasets\n",
    "        for i, header in enumerate(parsed_data.hdrs):\n",
    "            # Collecting charge_config data\n",
    "            if header.header_number == 0x10002:\n",
    "                # HDF5 groups require unique names if at same level of structure\n",
    "                charge_config_hdr_grp = charge_config_grp.create_group(f'charge_config_{i}')\n",
    "                charge_config_list.append(charge_config_hdr_grp)\n",
    "                hdrs_array.append(charge_config_hdr_grp)\n",
    "                for attr_name in ['charge_config_len', 'detector_code', 'tower_number',\n",
    "                                  'channel_post_amp', 'rtf_offset', 'delta_t', 'trigger_time',\n",
    "                                  'trace_len']:\n",
    "                    if hasattr(header.charge_config, attr_name):\n",
    "                        attr_value = getattr(header.charge_config, attr_name)\n",
    "                        charge_config_hdr_grp.create_dataset(attr_name, data=attr_value)\n",
    "                \n",
    "            # Collecting phonon_config data\n",
    "            elif header.header_number == 0x10001:\n",
    "                phonon_config_hdr_grp = phonon_config_grp.create_group(f'phonon_config_{i}')\n",
    "                phonon_config_list.append(header)\n",
    "                hdrs_array.append(phonon_config_hdr_grp)\n",
    "                for attr_name in ['phonon_config_len', 'detector_code', 'tower_number',\n",
    "                                  'post_amp_gain', 'qet_bias', 'squid_bias', 'squid_lockpoint',\n",
    "                                  'rtf_offset', 'variable_gain', 'delta_t', 'trigger_time', 'trace_len']:\n",
    "                    if hasattr(header.phonon_config, attr_name):\n",
    "                        attr_value = getattr(header.phonon_config, attr_name)\n",
    "                        phonon_config_hdr_grp.create_dataset(attr_name, data=attr_value)\n",
    "        \n",
    "        # Dictionary for creating groups\n",
    "        logical_record_options = {\n",
    "            0xA980: \"event_header\",\n",
    "            0x00000002: \"admin_rcrd\",\n",
    "            0x00000011: \"trace_data\",\n",
    "            0x00000021: \"soudan_history_buffer\",\n",
    "            0x00000060: \"gps_data\",\n",
    "            0x00000080: \"trigger_rcrd\",\n",
    "            0x00000081: \"tlb_trigger_mask_rcrd\",\n",
    "            0x00000022: \"detector_trigger_rates\",\n",
    "            0x00000031: \"veto_trigger_rates\",\n",
    "        }\n",
    "\n",
    "        # Creating groups that can hold each event's records\n",
    "        logical_rcrd_grp       = f.create_group('logical_rcrds')\n",
    "        pulse_grp              = logical_rcrd_grp.create_group('pulse_data')\n",
    "        event_hdr_grp          = logical_rcrd_grp.create_group('event_hdr')\n",
    "        admin_rcrd_grp         = logical_rcrd_grp.create_group('admin_rcrd')\n",
    "        trigger_rcrd_grp       = logical_rcrd_grp.create_group('trigger_rcrd')\n",
    "        tlb_trig_mask_rcrd_grp = logical_rcrd_grp.create_group('tlb_trig_mask_rcrd')\n",
    "        gps_data_grp           = logical_rcrd_grp.create_group('gps_data')\n",
    "        trace_data_grp         = logical_rcrd_grp.create_group('trace_data')\n",
    "        soudan_buffer_grp      = logical_rcrd_grp.create_group('soudan_buffer')\n",
    "        detector_trig_grp      = logical_rcrd_grp.create_group('detector_trigger_rates')\n",
    "        veto_trig_grp          = logical_rcrd_grp.create_group('veto_trigger_rates')\n",
    "\n",
    "        # Initializing arrays to store the created groups of logical_rcrd data\n",
    "        logical_rcrd_array       = []\n",
    "        event_hdr_array          = []\n",
    "        admin_rcrd_array         = []\n",
    "        trigger_rcrd_array       = []\n",
    "        tlb_trig_mask_rcrd_array = []\n",
    "        gps_data_array           = []\n",
    "        trace_data_array         = []\n",
    "        soudan_buffer_array      = []\n",
    "        detector_trig_array      = []\n",
    "        veto_trig_array          = []\n",
    "\n",
    "        # Array for storing data samples\n",
    "        pulse_array              = []\n",
    "\n",
    "        # Counters for iteration\n",
    "        event_count   = 0\n",
    "        admin_count   = 0\n",
    "        trigger_count = 0\n",
    "        tlb_count     = 0\n",
    "        gps_count     = 0\n",
    "        trace_count   = 0\n",
    "        pulse_count   = 0\n",
    "        soudan_count  = 0\n",
    "        detector_count = 0\n",
    "        veto_count     = 0\n",
    "        for i, record_option in enumerate(parsed_data.logical_rcrds):\n",
    "            # Handle event headers separately\n",
    "            if (record_option.next_section.next_header >> 16) == 0xA980:\n",
    "                # Storing event_hdr data\n",
    "                events = []\n",
    "                # Loop through attributes of event_hdr and store them in event_group_i\n",
    "                event_group_i = event_hdr_grp.create_group(f'event_group_{event_count}')\n",
    "                event_count += 1\n",
    "                for attr_name in ['event_header_word', 'event_size', 'event_identifier',\n",
    "                                'event_class', 'event_category', 'event_type']:\n",
    "                    if hasattr(record_option.next_section.section, attr_name):\n",
    "                        attr_value = getattr(record_option.next_section.section, attr_name)\n",
    "                        event_data = event_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                        events.append(event_data)\n",
    "                event_hdr_array.append(events)\n",
    "\n",
    "            for value, type in logical_record_options.items():\n",
    "                if record_option.next_section.next_header == value:\n",
    "                    if type == 'event_header':\n",
    "                        events = []\n",
    "                        # Loop through attributes of event_hdr and store them in event_group_i\n",
    "                        event_group_i = event_hdr_grp.create_group(f'{type}_group_{event_count}')\n",
    "                        event_count += 1\n",
    "                        for attr_name in ['event_header_word', 'event_size', 'event_identifier',\n",
    "                                        'event_class', 'event_category', 'event_type']:\n",
    "                            if hasattr(record_option.next_section.section, attr_name):\n",
    "                                attr_value = getattr(record_option.next_section.section, attr_name)\n",
    "                                event_data = event_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                                events.append(event_data)\n",
    "                        event_hdr_array.append(events)\n",
    "                        \n",
    "                    if type == 'admin_rcrd':\n",
    "                        # Store admin_rcrd data in an array\n",
    "                        admins = []\n",
    "                        admin_group_i = admin_rcrd_grp.create_group(f'{type}_group_{admin_count}')\n",
    "                        admin_count += 1\n",
    "                        for attr_name in ['admin_header', 'admin_len', 'series_number_1', 'series_number_2',\n",
    "                                        'event_number_in_series', 'seconds_from_epoch', 'time_from_last_event',\n",
    "                                        'live_time_from_last_event']:\n",
    "                            if hasattr(record_option.next_section.section, attr_name):\n",
    "                                attr_value = getattr(record_option.next_section.section, attr_name)\n",
    "                                admin_data = admin_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                                admins.append(admin_data)\n",
    "                        admin_rcrd_array.append(admins)\n",
    "                \n",
    "                    if type == 'trigger_rcrd':\n",
    "                        triggers = []\n",
    "                        trigger_group_i = trigger_rcrd_grp.create_group(f'{type}_group_{trigger_count}')\n",
    "                        trigger_count += 1\n",
    "                        for attr_name in ['trigger_header', 'trigger_len', 'trigger_time', 'individual_trigger_masks']:\n",
    "                            if hasattr(record_option.next_section.section, attr_name):\n",
    "                                attr_value = getattr(record_option.next_section.section, attr_name)\n",
    "                                trigger_data = trigger_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                                triggers.append(trigger_data)\n",
    "                        trigger_rcrd_array.append(triggers)\n",
    "\n",
    "                    if  type == 'tlb_trigger_mask_rcrd':\n",
    "                        tlb_trig_mask = []\n",
    "                        tlb_trig_group_i = tlb_trig_mask_rcrd_grp.create_group(f'{type}_group_{tlb_count}')\n",
    "                        tlb_count += 1\n",
    "                        for attr_name in ['tlb_mask_header', 'tlb_len', 'tower_mask']:\n",
    "                            if hasattr(record_option.next_section.section, attr_name):\n",
    "                                attr_value = getattr(record_option.next_section.section, attr_name)\n",
    "                                tlb_trig_data = tlb_trig_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                                tlb_trig_mask.append(tlb_trig_data)\n",
    "                        tlb_trig_mask_rcrd_array.append(tlb_trig_mask)\n",
    "\n",
    "                    if type == 'gps_data':\n",
    "                        # Storing gps_data\n",
    "                        gps = []\n",
    "                        # Loop through attributes of gps_data and store them in gps_data_group_i\n",
    "                        gps_data_group_i = gps_data_grp.create_group(f'{type}_group_{gps_count}')\n",
    "                        gps_count += 1\n",
    "                        # Only tlb_mask_header and length have values if length = 0\n",
    "                        if record_option.next_section.section.length == 0:\n",
    "                            for attr_name in ['tlb_mask_header', 'length']:\n",
    "                                if hasattr(record_option.next_section.section, attr_name):\n",
    "                                    attr_value = getattr(record_option.next_section.section, attr_name)\n",
    "                                    gps_dataset = gps_data_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                                    gps.append(gps_dataset)\n",
    "                        else:\n",
    "                            for attr_name in ['tlb_mask_header', 'length', 'gps_year_day', 'gps_status_hour_minute',\n",
    "                                            'gps_microsecs_from_gps_second']:\n",
    "                                if hasattr(record_option.next_section.section, attr_name):\n",
    "                                    attr_value = getattr(record_option.next_section.section, attr_name)\n",
    "                                    gps_dataset = gps_data_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                                    gps.append(gps_dataset)\n",
    "                        gps_data_array.append(gps)\n",
    "\n",
    "                    if type == \"trace_data\":\n",
    "                        if record_option.next_section.section.trace_rcrds:\n",
    "                            #print(f'trace # {trace_count}:\\n{record_option.next_section.section.trace_rcrds}')\n",
    "                            trace_record_group_i = trace_data_grp.create_group(f'{type}_group_{trace_count}')\n",
    "                            trace_count += 1\n",
    "                            #print(record_option.next_section.section.trace_rcrds)\n",
    "                            trace_rcrd = []\n",
    "                            for attr_name in ['trace_header', 'trace_len', 'trace_bookkeeping_header', 'bookkeeping_len',\n",
    "                                  'digitizer_base_address', 'digitizer_channel', 'detector_code', 'timebase_header',\n",
    "                                  'timebase_len', 't0_in_ns', 'delta_t_ns', 'num_of_points', 'second_trace_header',\n",
    "                                  'num_samples']:\n",
    "                                if hasattr(record_option.next_section.section.trace_rcrds, attr_name):\n",
    "                                    attr_value = getattr(record_option.next_section.section.trace_rcrds, attr_name)\n",
    "                                    trace_rcrd_dataset = trace_record_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                                    trace_rcrd.append(trace_rcrd_dataset)\n",
    "                            trace_data_array.append(trace_rcrd)\n",
    "\n",
    "                        if record_option.next_section.section.sample_data:            \n",
    "                            trace = []\n",
    "                            for data in record_option.next_section.section.sample_data:\n",
    "                                trace.append(data.sample_a)\n",
    "                                trace.append(data.sample_b)\n",
    "                            pulse_array.append(trace)\n",
    "\n",
    "                    if type == 'soudan_history_buffer':\n",
    "                        # Store soudan_history_buffer data in an array\n",
    "                        soudan_buffer = []\n",
    "                        soudan_buffer_group_i = soudan_buffer_grp.create_group(f'{type}_group_{soudan_count}')\n",
    "                        soudan_count += 1\n",
    "                        for attr_name in ['history_buffer_header', 'history_buffer_len', 'num_time_nvt', 'time_nvt',\n",
    "                              'num_veto_mask_words', 'time_n_minus_veto_mask', 'num_trigger_times', \n",
    "                              'trigger_times', 'num_trigger_mask_words', 'trig_times_minus_trig_mask']:\n",
    "                            if hasattr(record_option.next_section.section, attr_name):\n",
    "                                attr_value = getattr(record_option.next_section.section, attr_name)\n",
    "                                soudan_buffer_data = soudan_buffer_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                                soudan_buffer.append(soudan_buffer_data)\n",
    "                        soudan_buffer_array.append(soudan_buffer)\n",
    "\n",
    "                    if type == 'detector_trigger_rates':\n",
    "                        detector = []\n",
    "                        detector_group_i = detector_trig_grp.create_group(f'{type}_group_{detector_count}')\n",
    "                        detector_count += 1\n",
    "                        for attr_name in ['detector_trigger_header', 'len_to_next_header', 'clocking_interval',\n",
    "                                          'tower_number', 'detector_codes', 'j_codes', 'counter_values']:\n",
    "                            if hasattr(record_option.next_section.section, attr_name):\n",
    "                                attr_value = getattr(record_option.next_section.section, attr_name)\n",
    "                                detector_trig_data = detector_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                                detector.append(detector_trig_data)\n",
    "                        detector_trig_array.append(detector)\n",
    "                        \n",
    "                    if type == 'veto_trigger_rates':\n",
    "                        veto = []\n",
    "                        veto_group_i = veto_trig_grp.create_group(f'{type}_group_{veto_count}')\n",
    "                        veto_count += 1\n",
    "                        for attr_name in ['veto_trigger_header', 'len_to_next_header', 'clocking_interval',\n",
    "                                          'num_entries', 'detector_code', 'counter_value_det_code']:\n",
    "                            if hasattr(record_option.next_section.section, attr_name):\n",
    "                                attr_value = getattr(record_option.next_section.section, attr_name)\n",
    "                                veto_trig_data = veto_group_i.create_dataset(attr_name, data=attr_value)\n",
    "                                veto.append(veto_trig_data)\n",
    "                        veto_trig_array.append(veto)\n",
    "        \n",
    "        # Pulse array has varying lengths, causing an error in adding them to group               \n",
    "        #pulse_grp.create_dataset('traces', data=pulse_array)\n",
    "\n",
    "\n",
    "input_path  = \"../01120210_0727_F0114\"\n",
    "#input_path = \"/data3/afisher/test/01130208_1838_F0006\"\n",
    "output_path = \"../parsed.hdf5\"\n",
    "\n",
    "# For final files, save onto novateur network:\n",
    "#output_path = \"/data3/afisher/test/parsed_file.hdf5\"\n",
    "\n",
    "parse_file(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
